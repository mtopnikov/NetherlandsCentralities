{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralities Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict\n",
    "from shapely.geometry import LineString, Point\n",
    "from geopy.distance import geodesic\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cоздание матриц корреспонденции между коммунами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:/bachelors/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_list = os.listdir('translated_data_v2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = ['Покупки', 'Услуги', 'Туризм и рекреация', 'Другие виды досуга']\n",
    "commuter = ['Работа', 'Рабочая встреча']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Variables/mappers/communes_names_map.json') as infile:\n",
    "    names_map = json.load(infile)\n",
    "    \n",
    "all_names = np.unique(list(names_map.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matricies = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrMatrix(df_current):\n",
    "    \"\"\"Get correspondence matrix from datatable\"\"\"\n",
    "    df_current['route'] = df_current.apply(lambda row: tuple(sorted([row.geo_departure, row.geo_arrival])), axis = 1)\n",
    "    matrix = df_current.groupby('route')['uid_person'].nunique()\n",
    "    matrix.index = pd.MultiIndex.from_tuples(matrix.index)\n",
    "    matrix.index.set_names(['local_1', 'local_2'], inplace = True)\n",
    "    matrix.rename('flow', inplace = True)\n",
    "#     matrix.reset_index(inplace = True)\n",
    "    return matrix.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtopn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\mtopn\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (6,10,13,16,17,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets_list:\n",
    "    year = dataset.split('_')[1].split('.')[0]\n",
    "    df_current = pd.read_csv(f'translated_data_v2/{dataset}')\n",
    "    df_current['geo_departure'], df_current['geo_arrival'] = df_current['geo_departure'].map(names_map), df_current['geo_arrival'].map(names_map)\n",
    "    df_current.dropna(subset = ['geo_departure', 'geo_arrival'], inplace = True)\n",
    "    df_current = df_current[df_current.geo_departure != df_current.geo_arrival]\n",
    "    \n",
    "    matricies[year] = {\n",
    "        'total': get_corrMatrix(df_current),\n",
    "        'consumers' : get_corrMatrix(df_current[df_current.motiv_motivation.isin(consumer)]), \n",
    "        'commuters' : get_corrMatrix(df_current[df_current.motiv_motivation.isin(commuter)]),\n",
    "        'others' : get_corrMatrix(df_current[~df_current.motiv_motivation.isin(consumer + commuter)])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations as combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trips(current_data):\n",
    "    edges = defaultdict(dict)\n",
    "    indexes = current_data.index.to_flat_index()\n",
    "    for pair in tqdm(combo(all_names, 2)):\n",
    "        pair_r = pair[::-1]\n",
    "        if (pair in indexes) or (pair_r in indexes):\n",
    "            flow = current_data.loc[pair] + current_data.loc[pair[::-1]]\n",
    "            edges[(pair[0],pair[1])] = flow\n",
    "    edge_list = pd.DataFrame(edges, index = ['flow']).transpose().dropna()\n",
    "    edge_list.index.set_names(['local_1', 'local_2'], inplace = True)\n",
    "    edge_list.index.set_names(['local_1', 'local_2'], inplace = True)\n",
    "    edge_list.reset_index(inplace = True)\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trips(current_data):\n",
    "    edges = defaultdict(dict)\n",
    "    indexes = current_data.index.to_flat_index()\n",
    "    for pair in tqdm(combo(all_names, 2)):\n",
    "        try:\n",
    "            f1 = current_data.loc[pair]\n",
    "        except:\n",
    "            f1 = 0\n",
    "        try:\n",
    "            f2 = current_data.loc[pair[::-1]]\n",
    "        except:\n",
    "            f2 = 0\n",
    "        flow = f1 + f2\n",
    "        edges[(pair[0],pair[1])] = flow\n",
    "    edge_list = pd.DataFrame(edges, index = ['flow']).transpose().dropna()\n",
    "    edge_list.index.set_names(['local_1', 'local_2'], inplace = True)\n",
    "    edge_list.index.set_names(['local_1', 'local_2'], inplace = True)\n",
    "    edge_list.reset_index(inplace = True)\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Variables/mappers/coordinates_map_final.json') as infile:\n",
    "    coordinates_map = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(edge_list):   \n",
    "    edge_list = edge_list.assign(\n",
    "        lat_start = edge_list.local_1.map(coordinates_map).str['lat'],\n",
    "        lon_start = edge_list.local_1.map(coordinates_map).str['lon'],\n",
    "        lat_finish = edge_list.local_2.map(coordinates_map).str['lat'],\n",
    "        lon_finish = edge_list.local_2.map(coordinates_map).str['lon'],\n",
    "        distance = lambda frame: frame.apply(\n",
    "            lambda row: geodesic((row.lat_start, row.lon_start), (row.lat_finish, row.lon_finish)).kilometers,\n",
    "            axis = 1\n",
    "        ),\n",
    "        flow_weighted = lambda frame: frame.flow / frame.distance\n",
    "    ).assign(\n",
    "        flow = lambda frame: frame.flow / frame.flow.max(),\n",
    "        flow_weighted = lambda frame: frame.flow_weighted / frame.flow_weighted.max()\n",
    "    )\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geoLines(edge_list):\n",
    "    return gpd.GeoDataFrame(\n",
    "        edge_list,\n",
    "        geometry = [\n",
    "            LineString([(lon_start, lat_start),\n",
    "                       (lon_finish, lat_finish)]) for lat_start, lon_start, lat_finish, lon_finish in zip(edge_list.lat_start,\n",
    "                                                                                       edge_list.lon_start,\n",
    "                                                                                       edge_list.lat_finish,\n",
    "                                                                                       edge_list.lon_finish)],\n",
    "        crs = {'init' : 'epsg:4326'}\n",
    "    )\n",
    "\n",
    "def get_geoPoints(node_list):\n",
    "    return gpd.GeoDataFrame(\n",
    "        node_list,\n",
    "        geometry = [Point(xy) for xy in zip(node_list.lon, node_list.lat)],\n",
    "        crs = {'init' : 'epsg:4326'}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centrality_edges(graph):\n",
    "    edge_centrality = pd.DataFrame({\n",
    "        'flow_cent': nx.centrality.edge_current_flow_betweenness_centrality(\n",
    "            graph, weight='flow', normalized = False\n",
    "        ),\n",
    "        'flow_cent_weighted' : nx.centrality.edge_current_flow_betweenness_centrality(\n",
    "            graph, weight='flow_weighted', normalized = False\n",
    "        )\n",
    "    })\n",
    "    edge_centrality.index.set_names(['local_1', 'local_2'], inplace = True)\n",
    "    edge_centrality.reset_index(inplace = True)\n",
    "    return edge_centrality\n",
    "\n",
    "def centrality_nodes(graph):\n",
    "    node_centrality = pd.DataFrame({\n",
    "        'flow_cent': nx.centrality.current_flow_betweenness_centrality(\n",
    "            graph, weight='flow', normalized = False\n",
    "        ),\n",
    "        'flow_cent_weighted' : nx.centrality.current_flow_betweenness_centrality(\n",
    "            graph, weight='flow_weighted', normalized = False\n",
    "        )\n",
    "    })\n",
    "    node_centrality.index.set_names(['commune'], inplace = True)\n",
    "    node_centrality.reset_index(inplace = True)\n",
    "    return node_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_fuctions(year, tp):\n",
    "    total_system = matricies[year][tp]\n",
    "    edge_list = compute_metrics(total_system)\n",
    "    \n",
    "    graph = nx.from_pandas_edgelist(edge_list, 'local_1', 'local_2', ['flow', 'flow_weighted'])\n",
    "    edge_centrality = centrality_edges(graph)\n",
    "    node_centrality = centrality_nodes(graph).assign(\n",
    "        lat = lambda frame: frame.commune.map(coordinates_map).str['lat'],\n",
    "        lon = lambda frame: frame.commune.map(coordinates_map).str['lon']\n",
    "    )\n",
    "    edge_list = edge_list.merge(edge_centrality, on = ['local_1', 'local_2'])\n",
    "    \n",
    "#     os.makedirs(f'analysis/yearly_graphs/{tp}/')\n",
    "    get_geoLines(edge_list).to_file(\n",
    "        f'analysis/yearly_graphs/{tp}/edges_{year}.gpkg', driver = 'GPKG'\n",
    "    )\n",
    "    get_geoPoints(node_centrality).to_file(\n",
    "        f'analysis/yearly_graphs/{tp}/nodes_{year}.gpkg', driver = 'GPKG'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in matricies:\n",
    "    for tp in ['total', 'commuters', 'consumers', 'others']:\n",
    "        perform_fuctions(year, tp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
